%
%  An example of a bibliographical database for bibTeX
%
%  Recommended software for maintenance of *.bib files:
%    JabRef, http://jabref.sourceforge.net/
%
%  BEWARE:
%
%    *  If a name contains a capital letter, which must be kept such,
%       use curly brackets ({T}hailand, {HIV}).
%
%  ===========================================================================


@article{foundations_query_languages,
  author    = {Renzo Angles and
               Marcelo Arenas and
               Pablo Barcel{\'{o}} and
               Aidan Hogan and
               Juan L. Reutter and
               Domagoj Vrgoc},
  title     = {Foundations of Modern Graph Query Languages},
  journal   = {CoRR},
  volume    = {abs/1610.06264},
  year      = {2016},
  url       = {http://arxiv.org/abs/1610.06264},
  eprinttype = {arXiv},
  eprint    = {1610.06264},
  timestamp = {Mon, 13 Aug 2018 16:47:14 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/AnglesABHRV16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{sparql,
    title        = {{SPARQL} {Q}uery {L}anguage for {RDF} [online]},
    howpublished = {\url{https://www.w3.org/TR/rdf-sparql-query/}},
    note         = {Accessed: 2022-07-12}
}

@misc{sparql_update,
    title        = {{SPARQL} 1.1 {U}pdate [online]},
    howpublished = {\url{https://www.w3.org/TR/sparql11-update/}},
    note         = {Accessed: 2022-07-14}
}

@misc{sparql_propertypaths,
    title        = {{SPARQL} 1.1 {P}roperty {P}aths [online]},
    howpublished = {\url{https://www.w3.org/TR/sparql11-property-paths/}},
    note         = {Accessed: 2022-12-18}
}

@misc{opencypher,
    title        = {open{C}ypher [online]},
    howpublished = {\url{https://opencypher.org/}},
    note         = {Accessed: 2022-07-12}
}

@misc{rdf,
    title        = {{R}esource {D}escription {F}ramework [online]},
    howpublished = {\url{https://www.w3.org/TR/rdf11-concepts/}},
    note         = {Accessed: 2022-07-12}
}

@misc{gremlin,
    title        = {{G}remlin [online]},
    howpublished = {\url{https://tinkerpop.apache.org/gremlin.html}},
    note         = {Accessed: 2022-07-15}
}

@misc{pgql,
    title        = {{P}roperty {G}raph {Q}uery {L}anguage [online]},
    howpublished = {\url{https://pgql-lang.org/}},
    note         = {Accessed: 2022-12-17}
}

@misc{gcore,
  doi = {10.48550/ARXIV.1712.01550},
  
  url = {https://arxiv.org/abs/1712.01550},
  
  author = {Angles, Renzo and Arenas, Marcelo and Barceló, Pablo and Boncz, Peter and Fletcher, George H. L. and Gutierrez, Claudio and Lindaaker, Tobias and Paradies, Marcus and Plantikow, Stefan and Sequeda, Juan and van Rest, Oskar and Voigt, Hannes},
  
  keywords = {Databases (cs.DB), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {G-CORE: A Core for Future Graph Query Languages},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inbook{multimodel_look_forward,
author = {Liu, Zhen and Lu, Jiaheng and Gawlick, Dieter and Helskyaho, Heli and Pogossiants, Gregory and Wu, Zhe},
year = {2019},
month = {01},
pages = {16-29},
title = {Multi-model Database Management Systems - A Look Forward: VLDB 2018 Workshops, Poly and DMAH, Rio de Janeiro, Brazil, August 31, 2018, Revised Selected Papers},
isbn = {978-3-030-14176-9},
doi = {10.1007/978-3-030-14177-6_2}
}

@misc{polystores,
    author       = {Stonebraker, Michael},
    title        = {The case for polystores [online]},
    howpublished = {\url{http://wp.sigmod.org/?p=1629}},
    note         = {Accessed: 2022-12-19}
}

@INPROCEEDINGS{polystores2,  author={Kolev, Boyan and Pau, Raquel and Levchenko, Oleksandra and Valduriez, Patrick and Jiménez-Peris, Ricardo and Pereira, José},  booktitle={2016 IEEE International Conference on Big Data (Big Data)},   title={Benchmarking polystores: The CloudMdsQL experience},   year={2016},  volume={},  number={},  pages={2574-2579},  doi={10.1109/BigData.2016.7840899}}

@article{nosql,
    author = {Stonebraker, Michael},
    title = {SQL Databases v. NoSQL Databases},
    year = {2010},
    issue_date = {April 2010},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {53},
    number = {4},
    issn = {0001-0782},
    url = {https://doi.org/10.1145/1721654.1721659},
    doi = {10.1145/1721654.1721659},
    abstract = {The Communications Web site, http://cacm.acm.org, features more than a dozen bloggers in the BLOG@CACM community. In each issue of Communications, we'll publish excerpts from selected posts.twitterFollow us on Twitter at http://twitter.com/blogCACMMichael Stonebraker considers several performance arguments in favor of NoSQL databases---and finds them insufficient.},
    journal = {Commun. ACM},
    month = {apr},
    pages = {10–11},
    numpages = {2}
}

@article{multimodel_dbs,
    author = {Mihai (Rizescu), Gianina},
    year = {2020},
    month = {01},
    pages = {211-215},
    title = {Multi-Model Database Systems: The State of Affairs},
    volume = {XXVI},
    journal = {Annals of Dunarea de Jos University of Galati Fascicle I Economics and Applied Informatics},
    doi = {10.35219/eai15840409128}
}

@article{multimodel_dbs2,
    author = {Lu, Jiaheng and Holubov\'{a}, Irena},
    title = {Multi-Model Databases: A New Journey to Handle the Variety of Data},
    year = {2019},
    issue_date = {May 2020},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {52},
    number = {3},
    issn = {0360-0300},
    url = {https://doi.org/10.1145/3323214},
    doi = {10.1145/3323214},
    abstract = {The variety of data is one of the most challenging issues for the research and practice in data management systems. The data are naturally organized in different formats and models, including structured data, semi-structured data, and unstructured data. In this survey, we introduce the area of multi-model DBMSs that build a single database platform to manage multi-model data. Even though multi-model databases are a newly emerging area, in recent years, we have witnessed many database systems to embrace this category. We provide a general classification and multi-dimensional comparisons for the most popular multi-model databases. This comprehensive introduction on existing approaches and open problems, from the technique and application perspective, make this survey useful for motivating new multi-model database approaches, as well as serving as a technical reference for developing multi-model database applications.},
    journal = {ACM Comput. Surv.},
    month = {jun},
    articleno = {55},
    numpages = {38},
    keywords = {NoSQL database management systems, multi-model databases, Big data management}
}

@inproceedings{unibench,
    author = {Zhang, Chao and Lu, Jiaheng and Xu, Pengfei and Chen, Yuxing},
    year = {2019},
    month = {01},
    pages = {7-23},
    title = {UniBench: A Benchmark for Multi-model Database Management Systems: Recognizing Outstanding Ph.D. Research},
    isbn = {978-981-13-6054-1},
    doi = {10.1007/978-3-030-11404-6_2}
}

@article{codd,
    author = {Codd, E. F.},
    title = {A Relational Model of Data for Large Shared Data Banks},
    year = {1970},
    issue_date = {June 1970},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {13},
    number = {6},
    issn = {0001-0782},
    url = {https://doi.org/10.1145/362384.362685},
    doi = {10.1145/362384.362685},
    abstract = {Future users of large data banks must be protected from having to know how the data is organized in the machine (the internal representation). A prompting service which supplies such information is not a satisfactory solution. Activities of users at terminals and most application programs should remain unaffected when the internal representation of data is changed and even when some aspects of the external representation are changed. Changes in data representation will often be needed as a result of changes in query, update, and report traffic and natural growth in the types of stored information.Existing noninferential, formatted data systems provide users with tree-structured files or slightly more general network models of the data. In Section 1, inadequacies of these models are discussed. A model based on n-ary relations, a normal form for data base relations, and the concept of a universal data sublanguage are introduced. In Section 2, certain operations on relations (other than logical inference) are discussed and applied to the problems of redundancy and consistency in the user's model.},
    journal = {Commun. ACM},
    month = {jun},
    pages = {377–387},
    numpages = {11},
    keywords = {redundancy, data bank, data organization, retrieval language, data integrity, derivability, data structure, relations, join, hierarchies of data, composition, security, predicate calculus, networks of data, data base, consistency}
}

@inproceedings{relational_out,
    author = {Stonebraker, Michael and Madden, Samuel and Abadi, Daniel J. and Harizopoulos, Stavros and Hachem, Nabil and Helland, Pat},
    title = {The End of an Architectural Era: (It's Time for a Complete Rewrite)},
    year = {2007},
    isbn = {9781595936493},
    publisher = {VLDB Endowment},
    abstract = {In previous papers [SC05, SBC+07], some of us predicted the end of "one size fits all" as a commercial relational DBMS paradigm. These papers presented reasons and experimental evidence that showed that the major RDBMS vendors can be outperformed by 1--2 orders of magnitude by specialized engines in the data warehouse, stream processing, text, and scientific database markets.Assuming that specialized engines dominate these markets over time, the current relational DBMS code lines will be left with the business data processing (OLTP) market and hybrid markets where more than one kind of capability is required. In this paper we show that current RDBMSs can be beaten by nearly two orders of magnitude in the OLTP market as well. The experimental evidence comes from comparing a new OLTP prototype, H-Store, which we have built at M.I.T. to a popular RDBMS on the standard transactional benchmark, TPC-C.We conclude that the current RDBMS code lines, while attempting to be a "one size fits all" solution, in fact, excel at nothing. Hence, they are 25 year old legacy code lines that should be retired in favor of a collection of "from scratch" specialized engines. The DBMS vendors (and the research community) should start with a clean sheet of paper and design systems for tomorrow's requirements, not continue to push code lines and architectures designed for yesterday's needs.},
    booktitle = {Proceedings of the 33rd International Conference on Very Large Data Bases},
    pages = {1150–1160},
    numpages = {11},
    location = {Vienna, Austria},
    series = {VLDB '07}
}

@article{newsql,
    author = {Pavlo, Andrew and Aslett, Matthew},
    title = {What's Really New with NewSQL?},
    year = {2016},
    issue_date = {June 2016},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {45},
    number = {2},
    issn = {0163-5808},
    url = {https://doi.org/10.1145/3003665.3003674},
    doi = {10.1145/3003665.3003674},
    abstract = {A new class of database management systems (DBMSs) called NewSQL tout their ability to scale modern on-line transaction processing (OLTP) workloads in a way that is not possible with legacy systems. The term NewSQL was first used by one of the authors of this article in a 2011 business analysis report discussing the rise of new database systems as challengers to these established vendors (Oracle, IBM, Microsoft). The other author was working on what became one of the first examples of a NewSQL DBMS. Since then several companies and research projects have used this term (rightly and wrongly) to describe their systems.Given that relational DBMSs have been around for over four decades, it is justifiable to ask whether the claim of NewSQL's superiority is actually true or whether it is simply marketing. If they are indeed able to get better performance, then the next question is whether there is anything scientifically new about them that enables them to achieve these gains or is it just that hardware has advanced so much that now the bottlenecks from earlier years are no longer a problem.To do this, we first discuss the history of databases to understand how NewSQL systems came about. We then provide a detailed explanation of what the term NewSQL means and the different categories of systems that fall under this definition.},
    journal = {SIGMOD Rec.},
    month = {sep},
    pages = {45–55},
    numpages = {11}
}

@inbook{document_dbs,
    author = {Mishra, Omji and Lodhi, Pooja and Mehta, Shikha},
    year = {2018},
    month = {10},
    pages = {126-136},
    title = {Document Oriented NoSQL Databases: An Empirical Study},
    isbn = {978-981-10-8526-0},
    doi = {10.1007/978-981-10-8527-7_12}
}

@phdthesis{koupil_thesis,
    title    = {Modelling and Management of Multi-Model Data},
    school   = {Department of Software Engineering, Faculty of Mathematics and Physics, Charles University},
    author   = {Koupil, Pavel},
    year     = {2022},
}

@inproceedings{against_graph,
  title={The Case Against Specialized Graph Analytics Engines},
  author={Jing Fan and Adalbert Gerald Soosai Raj and Jignesh M. Patel},
  booktitle={Conference on Innovative Data Systems Research},
  year={2015}
}

@article{unified_representation,
    author = {Koupil, Pavel and Holubov{\'a}, Irena},
    year = {2022},
    month = {05},
    pages = {},
    title = {A unified representation and transformation of multi-model data using category theory},
    volume = {9},
    journal = {Journal of Big Data},
    doi = {10.1186/s40537-022-00613-3}
}

@inbook{one_model,
    author = {Svoboda, Martin and Čontoš, Pavel and Holubov{\'a}, Irena},
    year = {2021},
    month = {06},
    pages = {190-198},
    title = {Categorical Modeling of Multi-model Data: One Model to Rule Them All},
    isbn = {978-3-030-78427-0},
    doi = {10.1007/978-3-030-78428-7_15}
}

@article{mm_quecat,
    author = {Koupil, Pavel and Crha, Daniel and Holubov{\'a}, Irena},
    title = {MM-quecat: A Tool for Unified Querying of Multi-Model Data [not yet published]}
}

@article{er,
    author = {Chen, Peter Pin-Shan},
    title = {The Entity-Relationship Model—toward a Unified View of Data},
    year = {1976},
    issue_date = {March 1976},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {1},
    number = {1},
    issn = {0362-5915},
    url = {https://doi.org/10.1145/320434.320440},
    doi = {10.1145/320434.320440},
    abstract = {A data model, called the entity-relationship model, is proposed. This model incorporates some of the important semantic information about the real world. A special diagrammatic technique is introduced as a tool for database design. An example of database design and description using the model and the diagrammatic technique is given. Some implications for data integrity, information retrieval, and data manipulation are discussed.The entity-relationship model can be used as a basis for unification of different views of data: the network model, the relational model, and the entity set model. Semantic ambiguities in these models are analyzed. Possible ways to derive their views of data from the entity-relationship model are presented.},
    journal = {ACM Trans. Database Syst.},
    month = {mar},
    pages = {9–36},
    numpages = {28},
    keywords = {logigcal view of data, data integrity and consistency, data definition and manipulation, database design, network model, entity-relationship model, data models, entity set model, semantics of data, relational model, Data Base Task Group}
}

@article{inference,
    author = {Koupil, Pavel and Hricko, Sebastián and Holubov{\'a}, Irena},
    year = {2022},
    month = {08},
    pages = {},
    title = {A universal approach for multi-model schema inference},
    volume = {9},
    journal = {Journal of Big Data},
    doi = {10.1186/s40537-022-00645-9}
}

@inproceedings{evocat,
    author = {Koupil, Pavel and B\'{a}rt\'{\i}k, J\'{a}chym and Holubov\'{a}, Irena},
    title = {MM-Evocat: A Tool for Modelling and Evolution Management of Multi-Model Data},
    year = {2022},
    isbn = {9781450392365},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3511808.3557180},
    doi = {10.1145/3511808.3557180},
    abstract = {In this paper, we focus on the problem of evolution management of multi-model data. With the changing user requirements, the schema and the data need to be adapted to preserve the expected functionality of a multi-model application. We introduce a tool MM-evocat based on utilising the category theory. We show that the core of the tool, i.e., the categorical representation of multi-model data, enables us to grasp all the specifics of the individual models and their possible combinations. Its simple but powerful formal basis enables unique and robust support for evolution management.},
    booktitle = {Proceedings of the 31st ACM International Conference on Information \&; Knowledge Management},
    pages = {4892–4896},
    numpages = {5},
    keywords = {multi-model data, change propagation, evolution management},
    location = {Atlanta, GA, USA},
    series = {CIKM '22}
}

@book{category_theory,
  title={Basic category theory},
  author={Leinster, Tom},
  volume={143},
  year={2014},
  note={pages 1-26},
  publisher={Cambridge University Press}
}

@inproceedings{join_order,
    author = {Chen, Jin and Ye, Guanyu and Zhao, Yan and Liu, Shuncheng and Deng, Liwei and Chen, Xu and Zhou, Rui and Zheng, Kai},
    title = {Efficient Join Order Selection Learning with Graph-Based Representation},
    year = {2022},
    isbn = {9781450393850},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3534678.3539303},
    doi = {10.1145/3534678.3539303},
    abstract = {Join order selection plays an important role in DBMS query optimizers. The problem aims to find the optimal join order with the minimum cost, and usually becomes an NP-hard problem due to the exponentially increasing search space. Recent advanced studies attempt to use deep reinforcement learning (DRL) to generate better join plans than the ones provided by conventional query optimizers. However, DRL-based methods require time-consuming training, which is not suitable for online applications that need frequent periodic re-training. In this paper, we propose a novel framework, namely efficient Join Order selection learninG with Graph-basEd Representation (JOGGER). We firstly construct a schema graph based on the primary-foreign key relationships, from which table representations are well learned to capture the correlations between tables. The second component is the state representation, where a graph convolutional network is utilized to encode the query graph and a tailored-tree-based attention module is designed to encode the join plan. To speed up the convergence of DRL training process, we exploit the idea of curriculum learning, in which queries are incrementally added into the training set according to the level of difficulties. We conduct extensive experiments on JOB and TPC-H datasets, which demonstrate the effectiveness and efficiency of the proposed solutions.},
    booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
    pages = {97–107},
    numpages = {11},
    keywords = {database, graph representation, join order},
    location = {Washington DC, USA},
    series = {KDD '22}
}

@article{query_optimization,
author = {Jarke, Matthias and Koch, Jurgen},
title = {Query Optimization in Database Systems},
year = {1984},
issue_date = {June 1984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/356924.356928},
doi = {10.1145/356924.356928},
journal = {ACM Comput. Surv.},
month = {jun},
pages = {111–152},
numpages = {42}
}

@article{graph_tree_transform,
    author = {Xiong, Yingfei and Hu, Zhenjiang and Liu, Dongxi and Zhao, Haiyan and Mei, Hong and Takeichi, Masato},
    year = {2008},
    month = {01},
    pages = {},
    title = {Realizing Bidirectional Graph Transformations From Bidirectional Tree Transformations}
}

@inproceedings{pullbacks,
    author = {Spivak, David I. and Wisnesky, Ryan},
    title = {Relational Foundations for Functorial Data Migration},
    year = {2015},
    isbn = {9781450339025},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/2815072.2815075},
    doi = {10.1145/2815072.2815075},
    abstract = {We study the data transformation capabilities associated with schemas that are presented by directed multi-graphs and path equations. Unlike most approaches which treat graph-based schemas as abbreviations for relational schemas, we treat graph-based schemas as categories. A schema S is a finitely-presented category, and the collection of all S-instances forms a category, S-inst. A functor F between schemas S and T, which can be generated from a visual mapping between graphs, induces three adjoint data migration functors, Sigma_F : S-inst -&gt; T-inst, Pi_F : S-inst -&gt; T-inst, and Delta_F : T-inst -&gt; S-inst. We present an algebraic query language FQL based on these functors, prove that FQL is closed under composition, prove that FQL can be implemented with the select-project-product-union relational algebra (SPCU) extended with a key-generation operation, and prove that SPCU can be implemented with FQL.},
    booktitle = {Proceedings of the 15th Symposium on Database Programming Languages},
    pages = {21–28},
    numpages = {8},
    keywords = {Functorial data migration, Relational database theory, Category theory},
    location = {Pittsburgh, PA, USA},
    series = {DBPL 2015}
}

@inproceedings{multi_model_new_next,
  title={Multi-model Data Management: What's New and What's Next?},
  author={Jiaheng Lu and Irena Holubov{\'a}},
  booktitle={International Conference on Extending Database Technology},
  year={2017}
}

@book{gof,
  added-at = {2011-04-13T22:09:42.000+0200},
  asin = {0201633612},
  author = {Gamma, Erich and Helm, Richard and Johnson, Ralph E.},
  biburl = {https://www.bibsonomy.org/bibtex/286f0f1f1b5899d2594317169583391ce/sdo},
  description = {Design Patterns. Elements of Reusable Object-Oriented Software.: Amazon.de: Erich Gamma, Richard Helm, Ralph E. Johnson: Englische Bücher},
  dewey = {005.12},
  ean = {9780201633610},
  edition = {1st ed., Reprint.},
  interhash = {538f15d7e6e935d65579775dfe8b6ddd},
  intrahash = {86f0f1f1b5899d2594317169583391ce},
  isbn = {0201633612},
  keywords = {design gof pattern software},
  publisher = {Addison-Wesley Longman, Amsterdam},
  timestamp = {2011-04-13T22:09:42.000+0200},
  title = {Design Patterns. Elements of Reusable Object-Oriented Software.},
  url = {http://www.amazon.de/Patterns-Elements-Reusable-Object-Oriented-Software/dp/0201633612/ref=sr_1_1?ie=UTF8&qid=1302724786&sr=8-1},
  year = 1994
}

@inproceedings{mm_infer,
    author = {Koupil, Pavel and Hricko, Sebasti\'{a}n and Holubov\'{a}, Irena},
    title = {Schema Inference for Multi-Model Data},
    year = {2022},
    isbn = {9781450394666},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3550355.3552400},
    doi = {10.1145/3550355.3552400},
    abstract = {The knowledge of a structural schema of data is a crucial aspect of most data management tasks. Unfortunately, in many real-world scenarios, the data is not accompanied by it, and schema-inference approaches need to be utilised.In this paper, we focus on a specific and complex use case of multi-model data where several often contradictory features of the combined models must be considered. Hence, single-model approaches cannot be applied straightforwardly. In addition, the data often reach the scale of Big Data, and thus a scalable solution is inevitable. In our approach, we reflect all these challenges. In addition, we can also infer local integrity constraints as well as intra- and inter-model references. Last but not least, we can cope with cross-model data redundancy. Using a set of experiments, we prove the advantages of the proposed approach and we compare it with related work.},
    booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems},
    pages = {13–23},
    numpages = {11},
    keywords = {multi-model data, data redundancy, schema inference, cross-model references},
    location = {Montreal, Quebec, Canada},
    series = {MODELS '22}
}

@article{multicategory,
	doi = {10.14778/3476311.3476314},
  
	year = 2021,
	month = {jul},
  
	publisher = {Association for Computing Machinery ({ACM})},
  
	volume = {14},
  
	number = {12},
  
	pages = {2663--2666},
  
	author = {Valter Uotila and Jiaheng Lu and Dieter Gawlick and Zhen Hua Liu and Souripriya Das and Gregory Pogossiants},
  
	title = {{MultiCategory}},
  
	journal = {Proceedings of the {VLDB} Endowment}
}

@incollection{multicategory_theory,
	doi = {10.1007/978-3-030-93663-1_2},
  
	year = 2021,
	publisher = {Springer International Publishing},
  
	pages = {14--28},
  
	author = {Valter Uotila and Jiaheng Lu},
  
	title = {A Formal Category Theoretical Framework for~Multi-model Data Transformations},
  
	booktitle = {Heterogeneous Data Management, Polystores, and Analytics for Healthcare}
}

@article{cgood,
  title={CGOOD, a Categorical Graph-Oriented Object Data Model},
  author={Chris Tuijn and Marc Gyssens},
  journal={Theor. Comput. Sci.},
  year={1996},
  volume={160},
  pages={217-239}
}

@misc{spivak,
  doi = {10.48550/ARXIV.1602.03501},
  
  url = {https://arxiv.org/abs/1602.03501},
  
  author = {Schultz, Patrick and Spivak, David I. and Vasilakopoulou, Christina and Wisnesky, Ryan},
  
  keywords = {Category Theory (math.CT), Databases (cs.DB), FOS: Mathematics, FOS: Mathematics, FOS: Computer and information sciences, FOS: Computer and information sciences, 18C10, 18D05, 68P15},
  
  title = {Algebraic Databases},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {Creative Commons Attribution 4.0 International}
}


% EXAMPLE CITATIONS:

@BOOK{Andel07,
  title = {Základy matematické statistiky},
  publisher = {Matfyzpress},
  year = {2007},
  author = {Anděl, J.},
  address = {Praha},
  series = {Druhé opravené vydání},
  isbn = {80-7378-001-1}
}

@BOOK{Andel98,
  title = {Statistické metody},
  publisher = {Matfyzpress},
  year = {1998},
  author = {Anděl, J.},
  address = {Praha},
  series = {Druhé přepracované vydání},
  isbn = {80-85863-27-8}
}

@ARTICLE{Cox72,
  author = {Cox, D. R.},
  title = {Regression models and life-tables (with {D}iscussion)},
  journal = {Journal of the Royal Statistical Society, Series B},
  year = {1972},
  volume = {34},
  pages = {187--220},
  number = {2}
}

@ARTICLE{DempsterLairdRubin77,
  author = {Dempster, A. P. and Laird, N. M. and Rubin, D. B.},
  title = {Maximum likelihood from incomplete data via the {EM} algorithm},
  journal = {Journal of the Royal Statistical Society, Series B},
  year = {1977},
  volume = {39},
  pages = {1--38},
  number = {1}
}

@ARTICLE{Genberget08,
  author = {Genberg, B. L. and Kulich, M. and Kawichai, S. and Modiba, P. and
	Chingono, A. and Kilonzo, G. P. and Richter, L. and Pettifor, A.
	and Sweat, M. and Celentano, D. D.},
  title = {{HIV} risk behaviors in Sub-{S}aharan {A}frica and {N}orthern {T}hailand:
	{B}aseline behavioral data from project {A}ccept},
  journal = {Journal of Acquired Immune Deficiency Syndrome},
  year = {2008},
  volume = {49},
  pages = {309--319}
}

@ARTICLE{KaplanMeier58,
  author = {Kaplan, E. L. and Meier, P.},
  title = {Nonparametric estimation from incomplete observations},
  journal = {Journal of the American Statistical Association},
  year = {1958},
  volume = {53},
  pages = {457--481},
  number = {282}
}

@BOOK{LehmannCasella98,
  title = {Theory of Point Estimation},
  publisher = {Springer-Verlag},
  year = {1998},
  author = {Lehmann, E. L. and Casella, G.},
  address = {New York},
  series = {{S}econd {E}dition},
  isbn = {0-387-98502-6}
}

@ARTICLE{Student08,
  author = {Student},
  title = {On the probable error of the mean},
  journal = {Biometrika},
  year = {1908},
  volume = {6},
  pages = {1-25}
}
